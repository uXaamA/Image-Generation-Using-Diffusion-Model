# Diffusion Model - Image Generation



---

## ðŸš€ Project Overview

This project implements an **Image Generation system using Diffusion Models**. Diffusion models are state-of-the-art generative models that learn to create images by gradually removing noise from a random input, mimicking a reverse diffusion process.

This assignment demonstrates:

* Forward noise diffusion on clean animal images
* Training a denoising neural network
* Reversing the noise process to reconstruct images from noise

> âš¡ Powered entirely using **PyTorch**

---

## ðŸ“ Dataset

* **Classes Used**: 5 animal classes (e.g., cat, dog, lion, tiger, elephant)
* **Images per class**: 10â€“20
* **Total training images**: 50â€“100
* **Image Size**: Resized to 64Ã—64

Example structure:

```
animal_data/
â”œâ”€â”€ cat/
â”œâ”€â”€ dog/
â”œâ”€â”€ lion/
â”œâ”€â”€ tiger/
â””â”€â”€ elephant/
```

> âš  Ensure the dataset is well-balanced and formatted correctly before training.

---

## ðŸ”§ How to Run

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Train the Model

```bash
python M_Usama_MSDS24045.py --data_path animal_data --mode train
```

* Trains the model
* Saves noisy/clean/predicted images
* Logs loss curve

### 3. Generate New Image from Noise

```bash
python M_Usama_MSDS24045.py --data_path animal_data --mode sample
```

* Starts from pure noise and generates a denoised image
* Output saved in `samples/generated_sample.png`

### 4. Evaluation Notebook

Open `test_single_sample.ipynb` to:

* Load trained model
* Pass noise
* Visualize clean vs predicted image

---

## ðŸ§  Model Architecture

### Forward Process (Noise Addition)

* Custom function applies Gaussian noise progressively over `T=1000` timesteps
* Ensures images reach near-complete noise

### Denoising Model

* CNN-based model designed to remove noise at each step
* Learns reverse of the forward process

### Loss Function

* Custom **L2 Loss (MSE)** between predicted and actual clean image

---

## ðŸ§ª Training Configuration

| Parameter     | Value        |
| ------------- | ------------ |
| Epochs        | 10           |
| Batch Size    | 32           |
| Image Size    | 64x64        |
| Timesteps (T) | 1000         |
| Optimizer     | Adam         |
| Loss Function | MSE (Custom) |
| Framework     | PyTorch      |

---

## ðŸ“ˆ Results & Outputs

### âœ… Outputs Saved:

* Noisy samples per epoch: `samples/noisy_epochX.png`
* Denoised predictions: `samples/pred_epochX.png`
* Ground truths: `samples/clean_epochX.png`
* Loss curve: `samples/loss_graph.png`

### ðŸ“Š Training Loss:

* Loss decreases across epochs, indicating successful learning

* ![loss_graph](https://github.com/user-attachments/assets/eac541ea-b2c4-402c-96a1-636d659745bd)


### ðŸ–¼ï¸ Sample Results (Epoch 10):

| Clean Image | Noisy Input | Predicted Output |
| ----------- | ----------- | ---------------- |
| âœ…           | âŒ           | âœ…                |

![clean_epoch1](https://github.com/user-attachments/assets/93f7b581-7072-4346-b50c-c07bf2f509bd)
![noisy_epoch10](https://github.com/user-attachments/assets/e739f5b8-67f2-4e9a-8c44-2bfe16a20a4a)
![pred_epoch10](https://github.com/user-attachments/assets/6e8e1997-6c36-4fbc-9d4a-da4bc9968f9e)
---

## âš ï¸ Challenges Faced

* Shape mismatches during noise scheduling
* Debugging across multiple files was hard â†’ switched to single file structure
* Careful reshaping and normalization crucial to success

---

## ðŸ’¡ Learnings

* Deepened understanding of **forward and reverse diffusion**
* Experienced the challenges of training generative models
* Understood importance of noise scheduling
* Hands-on implementation of noise scheduling + denoising pipeline

---

## ðŸ§ª Folder Structure

```
M_Usama_MSDS24045/
â”œâ”€â”€ M_Usama_MSDS24045.py         # Full pipeline
â”œâ”€â”€ test_single_sample.ipynb     # Evaluation notebook
â”œâ”€â”€ Report.pdf                   # Detailed report + results
â”œâ”€â”€ requirements.txt             # Dependencies
â”œâ”€â”€ saved_models/
â”‚   â””â”€â”€ denoise_model.pt         # Trained model
â””â”€â”€ samples/
    â”œâ”€â”€ noisy_epochX.png
    â”œâ”€â”€ clean_epochX.png
    â”œâ”€â”€ pred_epochX.png
    â””â”€â”€ loss_graph.png
```

---

## ðŸ“š References

* [A Very Short Introduction to Diffusion Models](https://kailashahirwar.medium.com/a-very-short-introduction-to-diffusion-models-a84235e4e9ae)
* [Diffusion Models Made Easy](https://towardsdatascience.com/diffusion-models-made-easy-8414298ce4da)
* [SuperAnnotate on Diffusion Models](https://www.superannotate.com/blog/diffusion-models)
* [CMU Slides on Diffusion Models](https://deeplearning.cs.cmu.edu/S24/document/slides/Diffusion_Models.pdf)

---

## âœï¸ Author

**Name**: Muhammad Usama
MS Data Science 
**Institute**:Information Technology University Lahore
**Profession**: Technical Data Anlayst Haier Pakistan 

---

> *This project was completed as part of the Deep Learning coursework under academic guidance. All results are reproducible and open for inspection.*
